#### 损失函数和风险函数

##### 损失函数

给定一个输入 $X$ 和决策函数 $f$ ，$X$ 对于的真实值为 $Y$ ，而有决策函数得到的预测值为 $f(X)$，则可以定义一个损失函数 $L(Y, f(X))$ 来描述真实值和预测值之间的差异。

以下为几种常见的损失

- 0 - 1 损失
  $$
  L(Y, f(X)) = \begin{cases}1 & Y \ne f(X)\\ 0 & Y = f(X)\end{cases}
  $$

- 平方损失
  $$
  L(Y, f(X)) = (Y - f(X))^2
  $$

- 

等等……



##### 风险函数（期望损失）

损失函数 $L(Y, f(X))$ 的期望风险`expected risk`为
$$
\begin{align}
R_{exp} (f) &= E_p[L(Y, f(X))] \\\\
		&= \int_{\mathcal{X} \times \mathcal{Y}} L(y, f(x)) \times P(x, y)\ dxdy
\end{align}
$$
给定一个训练数据集
$$
T = \{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N) \}
$$
模型 $f(X)$ 关于该训练集的平均损失称为经验风险`empirical risk`，为
$$
R_{emp}(f) = {\frac{1}{N}}\sum_{i=1}^{N}L(y_i, f(x_i))
$$


> 期望风险 $R_{exp} (f)$ 为模型关于联合分布的期望损失，经验风险 $R_{emp}(f)$ 是模型关于训练样本集的平均损失。



#### 弱大数定律

假设随机变量$X_1, X_2, ... , X_n, ....$ 是独立同分布的，且有全体期望 $E(X_k) = \mu$，取前 $n$ 个序列，当 $n \rightarrow \infty$ 时有
$$
\forall \epsilon \gt 0 \quad p\{ (\mu - \frac{\sum_{i=1}^{n}X_i}{n}) \lt \epsilon \} = 1
$$

根据大数定律当 $N \rightarrow \infty$ 时，有经验风险趋向于期望风险
$$
R_{emp}(f) \rightarrow R_{exp}(f)
$$



#### 正则化

正则化有如下的一般形式
$$
\min_{f \in \mathcal{F}} {\frac{1}{N}}\sum_{i = 1}^{N}L(y_i, f(x_i)) + \lambda J(f) \quad \lambda > 0
$$
其中 $\lambda J(f)$ 为正则化项，$J(f)$ 与模型的复杂度呈正相关，$\lambda$ 为调整经验风险与模型复杂度之间关系的系数

- $L_1$ 范数为 $\lambda ||w||$ （各参数绝对值之和），其倾向于将各参数调整为 $0$，故可产生稀疏权值矩阵，一般用于特征选择
- $L_2$ 范数为 $\frac{\lambda}{2} ||w||^2$，因为要进行开方操作，故其主要影响绝对值大的参数，一般用于防止模型过拟合

正则化的作用就是选择经验风险和模型复杂度同时较小的模型。



#### 泛化能力

泛化能力指的是模型对未知数据的预测能力。

泛化误差定义如下
$$
\begin{align}
R_{exp} (\hat{f}) &= E_p[L(Y, \hat{f}(X))] \\\\
		&= \int_{\mathcal{X} \times \mathcal{Y}} L(y, \hat{f}(x)) \times P(x, y)\ dxdy
\end{align}
$$
其中$\hat{f}(X)$表示上面的 **^** 当前的模型是通过学习得到的。



##### 泛化误差上界

对于二分类问题，当假设空间是有限个函数的集合 $\mathcal{F} = \{f_1, f_2, ..., f_d\}$ 时，对于 $\forall f \in \mathcal{F}$，至少以概率 $1 - \delta, \quad 0 < \delta < 1$  ，以下不等式成立
$$
\begin{align}
& R_{exp}(f) \leq \hat{R}_{emp}(f) + \epsilon(d, N, \delta) \\\\
& \epsilon(d, N, \delta) = \sqrt{\frac{1}{2N}(logd + log\frac{1}{\delta})}
\end{align}
$$




#### 生成模型与判别模型





#### 监督学习应用





#### 习题

