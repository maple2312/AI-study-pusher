### 感知机



#### 感知机模型的定义

假设输入空间（特征空间）是 $\mathcal{X} \subseteq R^n$ ，输出空间是 $\mathcal{Y} = \{-1, 1\}$

输入 $x \in \mathcal{X}$表示输入实例的特征向量，输出 $y \in \mathcal{Y}$ 表示实例的类别。有驶入空间到输出空间的映射为：
$$
f(x) = sign(w^Tx + b)
$$


#### 感知机学习算法

##### 损失函数

定义感知机的损失函数为误分类点到超平面的距离且不考虑 ${1 \over ||w||} $ ，定义$M$为误分类点集合，有
$$
L(w,b) =- \sum_{x_i \in M} y_i * (w^Tx + b)
$$

> 若考虑 ${1 \over ||w||} $ 则损失函数定义为
> $$
> L(w,b) = -{1 \over ||w||}  \sum_{x_i \in M} y_i * (w^Tx + b)
> $$
> 为什么可以不用考虑呢？
>
> 因为存在一个 $w' = kw$ 有 $||w'|| = 1$ 这时 $w^{'T}x+b' = 0$ 与 $w^Tx+b = 0$ 是同一条直线

采用梯度下降法有
$$
{\partial L \over \partial w} = - \sum_{x_i \in M} y_i x_i \\\\
{\partial L \over \partial b} = - \sum_{x_i \in M} y_i
$$


##### 算法描述

输入：训练数据集 $T=\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}$ ，模型参数$w$、$b$，学习率 $\eta  \quad 0 < \eta \leq 1$

输出：感知机模型 $f(x) = sign(w^Tx + b)$

训练过程：

1. 给定模型参数$w$、$b$的初值

2. 在训练集中找到一个选择点 $(x_i, y_i) \quad i = 1, 2, ..., N$ （采用的是随机梯度下降`SGD`）

   若 $y_i \times f(x_i) < 0$ 则说明找到了一个误分类点，接下来更新 $w$、$b$ 的值
   $$
   w \leftarrow w + \eta y_ix_i \\
   b \leftarrow w + \eta y_i \\
   $$

3. 转到 2 直到训练集中没有误分类点



##### 感知机学习算法的收敛性证明





#### 习题

一、已知一个有训练数据集，其正例点是$x_1=(3,3)，x_1=(4,3)$,负例点是$x_3=(1,1)$，请用代码求出分类超平面并给出感知机模型。

