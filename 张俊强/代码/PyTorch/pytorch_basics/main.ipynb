{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae69459",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.utils.data.Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c2ce9c470ee9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mTF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.utils.data.Dataset'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c7bf7",
   "metadata": {},
   "source": [
    "### 1. Basic autograd example 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1988ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Create Tensor\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph\n",
    "y = w * x + b # y = 2 * x + 3\n",
    "\n",
    "# Compute Gradients\n",
    "y.backward()\n",
    "\n",
    "# get value\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffec766",
   "metadata": {},
   "source": [
    "### 2. Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8006b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[ 0.5376,  0.1540,  0.3469],\n",
      "        [-0.0983, -0.0502, -0.5432]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([ 0.3768, -0.2052], requires_grad=True)\n",
      "dL/dw =  None\n",
      "dL/db =  None\n",
      "Loss =  2.5665335655212402\n"
     ]
    }
   ],
   "source": [
    "# Create tensor of shape(10, 3) as (10, 2)\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# print(x.data)\n",
    "# print(y.data)\n",
    "\n",
    "linear = nn.Linear(3, 2)\n",
    "print('w: ', linear.weight)\n",
    "print('b: ', linear.bias)\n",
    "\n",
    "# Build loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass\n",
    "pred = linear(x)\n",
    "\n",
    "# Compute loss\n",
    "print('dL/dw = ', linear.weight.grad)\n",
    "print('dL/db = ', linear.bias.grad)\n",
    "\n",
    "# 1-step gradient descent\n",
    "optimizer.step()\n",
    "\n",
    "# print out loss\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "\n",
    "print('Loss = ', loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0630ae",
   "metadata": {},
   "source": [
    "### 3. Loading data from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eab2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "y = torch.from_numpy(x)\n",
    "z = y.numpy()\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0320c",
   "metadata": {},
   "source": [
    "### 4. Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdae4ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Download and construct cifar-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/',\n",
    "    download=True,\n",
    "    transform=TF.ToTensor(),\n",
    "    train=True\n",
    ")\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# When iter starts, load data from files\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini batch images and labels\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of the dataloader \n",
    "for images, labels in train_loader:\n",
    "    # Training code should be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3374b70",
   "metadata": {},
   "source": [
    "### 5. Input pipeline for custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cbb4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should build your custom dataset ad below\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # 1. Initial file paths or a list of file names\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file(e.g using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (e.g torchvision.Transform)\n",
    "        # 3. Return a data pair (e.g. image and label)\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return 0\n",
    "\n",
    "    \n",
    "# You can then use the prebuilt data loader\n",
    "# custom_dataset = CustomDataset()\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=custom_dataset,\n",
    "#     batch_size=64,\n",
    "#     shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0f4cc",
   "metadata": {},
   "source": [
    "### 6. Pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d2be07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "# Download and Load ResNet-18\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "# 微调模型\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Replace the top layer for finetuning\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)\n",
    "\n",
    "# Porwad pass\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ac3cd",
   "metadata": {},
   "source": [
    "### 7. Save and load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5218aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and load the entire model\n",
    "torch.save(resnet, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')\n",
    "\n",
    "# Save and load the model parameters\n",
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a24254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
