<div align="center" style="font-size: 24px; font-weight: bold">机器学习测试卷一</div>

一、基础知识（$2 \times 25$）

1. 给定一个输入 $X$ 和决策函数 $f$ ，$X$ 对于的真实值为 $Y$ ，而决策函数得到的预测值为 $f(X)$，则可以定义一个损失函数 $L(Y, f(X))$ 来描述真实值和预测值之间的差异。 $0-1$ 损失定义为，$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$，平方损失定义为$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$，对数损失定义为$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$。

2. 给定训练数据集$T=\{(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)\}$，其中$x_i \in \mathcal{X} = R^n$，$y_i \in \mathcal{Y} = \{-1, +1\}$，$i=1,2,\ldots,N$；学习率$\eta (0 < \eta \leqslant 1)$；参数$w, b$。

   感知机模型 $f(x)= \_\_\_\_\_\_\_\_\_\_\_\_\_\_$  ，对于数据$(x_i,y_i)$为误分类点的判断依据为$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$，使用`SGD`对参数进行更新，若$(x_i,y_i)$为误分类点，则参数$w、b$更新公式为：$w = \_\_\_\_\_\_\_\_\_\_、b = \_\_\_\_\_\_\_\_\_\_$。

3. 朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测，输入$X = (x^{(1)}, x^{(2)}, ..., x^{(n)})$ ，$Y = \{c_1, c_2, ..., c_K\}$

   有在条件$X$的情况下其类别为$Y$的概率公式为：
   $$
   P(Y|X) = \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
   $$
   将输入$X$分到后验概率最大的类$y$的表达式为：
   $$
   y = \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
   $$
   
4. 信息增益作为划分数据集的特征，存在偏向于$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$的特征，所以可以使用信息增益比来划分，对于样本$D$，特征$A$，$A$对样本$D$的信息增益是$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$，信息增益比是$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$和$\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_$的比值。

5. SMO算法是一种启发式算法，其基本思路是：如果所有变量的解都满足此最优化问题的KKT条件，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。SMO算法在每个子问题中选择$\_\_\_\_\_$ 个变量进行优化，且至少有一个不满足KKT条件，然后求解$\_\_\_\_\_\_$ 问题更新它们。

6. 





二、计算题（$2 \times 15$）

1. 如下为某公司统计的数据表$D$

   | 计数 | 年龄 A1 | 收入A2 | 学生A3 | 信誉A4 | 归类Y：买计算机？ |
   | ---- | ------- | ------ | ------ | ------ | ----------------- |
   | 1    | 青      | 高     | 否     | 良     | 不买              |
   | 2    | 青      | 高     | 否     | 优     | 不买              |
   | 3    | 中      | 高     | 否     | 良     | 买                |
   | 4    | 老      | 中     | 否     | 良     | 买                |
   | 5    | 老      | 低     | 是     | 良     | 买                |
   | 6    | 老      | 低     | 是     | 优     | 不买              |
   | 7    | 中      | 低     | 是     | 优     | 买                |
   | 8    | 青      | 中     | 否     | 良     | 不买              |
   | 9    | 青      | 低     | 是     | 良     | 买                |
   | 10   | 老      | 中     | 是     | 良     | 买                |
   | 11   | 青      | 中     | 是     | 优     | 买                |
   | 1 2  | 中      | 中     | 否     | 优     | 买                |
   | 13   | 中      | 高     | 是     | 良     | 买                |
   | 14   | 老      | 中     | 否     | 优     | 不买              |
   | 15   | 老      | 中     | 否     | 优     | 买                |

   使用ID3算法计算下面问题

   $(1)$ 计算样本$D$的信息熵$H(D)$

   $(2)$ 计算出各特征$A_i$对样本$D$的经验条件熵$H(A_i|D)$并计算出信息增益$G(A_i|D)$，其中 $i = 1,2,3,4$

   $(3)$ 画出决策树





















2. 已知一个有训练数据集，其正例点是$x_1=(1,2)^T，x_2=(2,3)^T，x_2=(3,3)^T$,负例点是$x_4=(2,1)^T，x_5=(3, 2)^T$，请求出最大间隔分类超平面并给出分类决策函数以及支持向量。



















三、综合题（$2 \times 10$）



